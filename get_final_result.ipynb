{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a0573d-53dd-493b-9796-57f74e9c9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from process_data import pre_process\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import xavier_uniform_, xavier_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8a8403-aacf-4a1b-9b11-7d042cb73218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4REC(nn.Module):\n",
    "    def __init__(self, input_size, output_size, embedding_size, hidden_size, n_layers=1, dp=0.3):\n",
    "        \"\"\"\n",
    "        input_size = output_size = num_item\n",
    "        \"\"\"\n",
    "        super(GRU4REC, self).__init__()\n",
    "\n",
    "        # === 定义参数 ===\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout = dp\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # === 定义layers ===\n",
    "        # 1. embedding layer\n",
    "        self.item_embedding = nn.Embedding(self.input_size, self.embedding_size, padding_idx=0)\n",
    "        self.emb_dropout = nn.Dropout(self.dropout)\n",
    "        # 2. GRU layer\n",
    "        self.gru = nn.GRU(input_size=self.embedding_size,\n",
    "                          hidden_size=self.hidden_size,\n",
    "                          num_layers=self.n_layers,\n",
    "                          bias=False,\n",
    "                          batch_first=True)\n",
    "        # 3. feedforward layers\n",
    "        self.feedforward = nn.Linear(self.hidden_size, self.embedding_size)\n",
    "\n",
    "        # === 初始化参数 ===\n",
    "        xavier_normal_(self.item_embedding.weight)\n",
    "        xavier_uniform_(self.gru.weight_hh_l0)\n",
    "        xavier_uniform_(self.gru.weight_ih_l0)\n",
    "\n",
    "    def forward(self, item_seq, item_seq_len):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            item_seq, shape = (batch_size, seq_len)\n",
    "        Return:\n",
    "            scores, shape = (batch_size*seq_len, output_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # embedding layer\n",
    "        seq_embedding = self.item_embedding(item_seq)\n",
    "        gru_input = self.emb_dropout(seq_embedding)\n",
    "\n",
    "        # GRU layer\n",
    "        gru_output, _ = self.gru(gru_input)\n",
    "\n",
    "        # feed forward layer\n",
    "        output = self.feedforward(gru_output)\n",
    "\n",
    "        # 映射回item_size空间，最后一个维度的embedding_size -> input_size = item_size\n",
    "        output = output @ self.item_embedding.weight.T\n",
    "\n",
    "        return output.reshape(-1, output.shape[-1])\n",
    "\n",
    "    def predict(self, item_seq):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            item_seq, shape = (batch_size, seq_len)\n",
    "        Return:\n",
    "            final_score, shape = (batch_size, item_size)\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            seq_embedding = self.item_embedding(item_seq)  # [bs, seq_len, embedding_size]\n",
    "            gru_output, _ = self.gru(seq_embedding)  # [bs, seq_len, hidden_size]\n",
    "            gru_output = self.feedforward(gru_output)  # [bs, seq_len, embedding_size]\n",
    "            scores = gru_output @ self.item_embedding.weight.T  # [bs, seq_len, item_size]\n",
    "        self.train()\n",
    "        final_score = scores[:, -1, :]  # 取最后一个timestep，[bs, item_size]\n",
    "        return final_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d34089-4a9e-45ca-bf4a-c398aeb15f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetResult:\n",
    "    def __init__(self, dataset='Beauty', best_model='gru4rec'):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.dataset = dataset\n",
    "        _ = pre_process(file=dataset)\n",
    "        self.item2index = _[2]\n",
    "        self.index2item = _[3]\n",
    "        self.test_data = self.process_data()\n",
    "        self.loader = self.get_batches(batch_size=128)\n",
    "\n",
    "        # 建立和读取model\n",
    "        if self.device == \"cuda\":\n",
    "            state_dict = torch.load(f'pretrained_model/{dataset}/{best_model}.pt')\n",
    "        else:\n",
    "            state_dict = torch.load(f'pretrained_model/{dataset}/{best_model}.pt',\n",
    "                                    map_location=torch.device('cpu'))\n",
    "        item_size = state_dict['item_embedding.weight'].shape[0]\n",
    "        self.model = GRU4REC(input_size=item_size,\n",
    "                             output_size=item_size,\n",
    "                             embedding_size=128,\n",
    "                             hidden_size=128,\n",
    "                             dp=0).to(self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def process_data(self):\n",
    "        data = pd.read_csv(f\"./dataset/Amazon_{self.dataset}/test_sessions.csv\")\n",
    "        data[\"session\"] = data.session.apply(eval)\n",
    "\n",
    "        # 将item编码为整数\n",
    "        item2index = self.item2index\n",
    "        def f1(input):\n",
    "            if isinstance(input, list):\n",
    "                return [item2index[input[i]] for i in range(len(input))]\n",
    "            else:\n",
    "                return item2index[input]\n",
    "\n",
    "        data[\"session\"] = data[\"session\"].apply(f1)\n",
    "        data = data.reset_index(drop=True)\n",
    "        return data\n",
    "\n",
    "    def get_batches(self, batch_size):\n",
    "        dataset = self.test_data\n",
    "        # indices，记录每条session的索引和长度\n",
    "        indices = [(i, len(s)) for i, s in enumerate(dataset.session)]\n",
    "        random.shuffle(indices)\n",
    "        # 以100*batch_size为一组, 按照session长度进行排序后加入pooled_indices\n",
    "        pooled_indices = []\n",
    "        for i in range(0, len(indices), batch_size*100):\n",
    "            curr_data_indices = sorted(indices[i: i + batch_size*100],\n",
    "                                       key=lambda x: x[1],\n",
    "                                       reverse=True)\n",
    "            pooled_indices.extend(curr_data_indices)\n",
    "        pooled_indices = [x[0] for x in pooled_indices]\n",
    "        # 分的每一块作为一个batch，得到对应的索引\n",
    "        batches_idx = []\n",
    "        for i in range(0, len(pooled_indices), batch_size):\n",
    "            batches_idx.append(pooled_indices[i: i + batch_size])\n",
    "        # 根据索引获取batch数据\n",
    "        batches = []\n",
    "        for batch_idx in batches_idx:\n",
    "            batch = dataset.loc[batch_idx, ['session']]\n",
    "            rec_list = []\n",
    "            for record in batch.session:\n",
    "                rec_list.append(torch.tensor(record))\n",
    "            # 用0填充\n",
    "            X = pad_sequence(rec_list, padding_value=0, batch_first=True)  # [batch_size, max_seq_len]\n",
    "            batches.append(X)\n",
    "        return batches\n",
    "\n",
    "    def get_result(self):\n",
    "        def remove_padding(s):\n",
    "            ss = []\n",
    "            for item in s:\n",
    "                if item != 0:\n",
    "                    ss.append(item)\n",
    "            return ss\n",
    "\n",
    "        session = []\n",
    "        predict = []\n",
    "        for batch in self.loader:\n",
    "            X = batch.to(self.device)  # [batch_size, seq_len]\n",
    "            scores = self.model.predict(X)  # [batch_size, item_size]\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                # 去除零填充，获取session\n",
    "                s_i = X[i].tolist()  # [seq_len]\n",
    "                session_i = remove_padding(s_i)\n",
    "                session.append(session_i)\n",
    "\n",
    "                # 获取该session的预测top@20, 除去item 0\n",
    "                score_i = scores[i]  # [item_size]\n",
    "                top_i = score_i.argsort(descending=True).tolist()\n",
    "                if 0 not in top_i[:20]:\n",
    "                    top_k = top_i[:20]\n",
    "                else:\n",
    "                    top_k = top_i[:21]\n",
    "                    top_k.remove(0)\n",
    "                predict.append(top_k)\n",
    "\n",
    "        # 转换为原始的item id\n",
    "        index2item = self.index2item\n",
    "        def f(input):\n",
    "            if isinstance(input, list):\n",
    "                return [index2item[input[i]] for i in range(len(input))]\n",
    "            else:\n",
    "                return index2item[input]\n",
    "\n",
    "        test_result = {'session': session, 'predict': predict}\n",
    "        test_result = pd.DataFrame(test_result)\n",
    "        test_result['session'] = test_result['session'].apply(f)\n",
    "        test_result['predict'] = test_result['predict'].apply(f)\n",
    "\n",
    "        # 转换为字符形式\n",
    "        test_result['session'] = test_result['session'].apply(lambda x: str(x))\n",
    "        test_result['predict'] = test_result['predict'].apply(lambda x: str(x))\n",
    "\n",
    "        return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63b5e8c-d7ee-472d-a47a-2bf838b51322",
   "metadata": {
    "id": "WRtbiJ2rCChC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beauty = GetResult(dataset='Beauty').get_result()\n",
    "cell = GetResult(dataset='Cell').get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f85df7d-32bf-488b-89c0-7ec45b031403",
   "metadata": {},
   "outputs": [],
   "source": [
    "beauty.to_csv('results/test_result_beauty.csv', index=False)\n",
    "cell.to_csv('results/test_result_cell.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff338da3-044f-425e-95ff-fd1ecefd9cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
